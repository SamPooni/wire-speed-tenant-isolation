<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Wire-Speed Tenant Isolation Guide | CS²B Technologies</title>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <style>
        :root {
            --bg: #0d1117;
            --text: #c9d1d9;
            --heading: #58a6ff;
            --border: #30363d;
            --code-bg: #161b22;
            --accent: #238636;
            --cyan: #00f0ff;
        }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            background: var(--bg);
            color: var(--text);
            line-height: 1.6;
            margin: 0;
            padding: 40px;
            max-width: 1000px;
            margin: 0 auto;
        }
        h1, h2, h3, h4 { color: var(--heading); }
        h1, h2 { border-bottom: 1px solid var(--border); padding-bottom: 10px; }
        h1 { font-size: 2.2em; }
        h2 { font-size: 1.8em; margin-top: 40px; }
        h3 { font-size: 1.4em; margin-top: 30px; }
        a { color: var(--heading); }
        pre {
            background: var(--code-bg);
            border: 1px solid var(--border);
            border-radius: 6px;
            padding: 16px;
            overflow-x: auto;
        }
        code {
            font-family: 'SFMono-Regular', Consolas, monospace;
            background: var(--code-bg);
            padding: 2px 6px;
            border-radius: 4px;
            font-size: 0.9em;
        }
        pre code { background: none; padding: 0; }
        table {
            border-collapse: collapse;
            width: 100%;
            margin: 16px 0;
        }
        th, td {
            border: 1px solid var(--border);
            padding: 10px;
            text-align: left;
        }
        th { background: var(--code-bg); color: var(--heading); }
        tr:nth-child(even) { background: rgba(48,54,61,0.3); }
        blockquote {
            border-left: 4px solid var(--heading);
            margin: 16px 0;
            padding: 10px 20px;
            background: rgba(88,166,255,0.1);
            border-radius: 0 6px 6px 0;
        }
        hr { border: none; border-top: 1px solid var(--border); margin: 24px 0; }
        
        .mermaid {
            background: var(--code-bg);
            border: 1px solid var(--border);
            border-radius: 8px;
            padding: 20px;
            margin: 20px 0;
            text-align: center;
            overflow-x: auto;
        }
        .mermaid svg {
            max-width: 100%;
            height: auto;
        }
        
        .loading {
            text-align: center;
            padding: 60px;
            font-size: 1.2em;
            color: var(--heading);
        }
        
        .header-brand {
            display: flex;
            align-items: center;
            gap: 12px;
            margin-bottom: 20px;
            padding-bottom: 20px;
            border-bottom: 1px solid var(--border);
        }
        .header-brand .logo {
            font-size: 24px;
            font-weight: 700;
            color: var(--cyan);
        }
        .header-brand .logo sup {
            font-size: 14px;
        }
        .header-brand .tagline {
            font-size: 12px;
            color: #6e6e73;
            text-transform: uppercase;
            letter-spacing: 0.1em;
        }
        
        @media (max-width: 768px) {
            body { padding: 20px; }
            table { font-size: 0.9em; }
            .mermaid { padding: 10px; }
        }
    </style>
</head>
<body>
    <div class="header-brand">
        <div>
            <div class="logo">CS<sup>2</sup>B</div>
            <div class="tagline">Cognitive Systems × Scalable Behaviors</div>
        </div>
    </div>
    <div id="content" class="loading">Loading guide...</div>
    
    <script>
        mermaid.initialize({
            startOnLoad: false,
            theme: 'dark',
            themeVariables: {
                primaryColor: '#238636',
                primaryTextColor: '#c9d1d9',
                primaryBorderColor: '#30363d',
                lineColor: '#58a6ff',
                secondaryColor: '#161b22',
                tertiaryColor: '#0d1117',
                background: '#161b22',
                mainBkg: '#161b22',
                nodeBorder: '#30363d',
                clusterBkg: '#161b22',
                clusterBorder: '#30363d',
                titleColor: '#58a6ff',
                edgeLabelBackground: '#161b22'
            },
            flowchart: { useMaxWidth: true, htmlLabels: true, curve: 'basis' },
            securityLevel: 'loose'
        });

        const renderer = new marked.Renderer();
        const originalCodeRenderer = renderer.code.bind(renderer);
        renderer.code = function(code, language) {
            if (language === 'mermaid') {
                return '<div class="mermaid">' + code + '</div>';
            }
            return originalCodeRenderer(code, language);
        };
        marked.setOptions({ renderer: renderer, gfm: true, breaks: false });

        const md = "# Wire-Speed Tenant Isolation: Complete Technical Guide\n\n> **A comprehensive guide to implementing ultra-low latency, hardware-enforced tenant isolation in modern AI and cloud infrastructure**\n\n---\n\n## Table of Contents\n\n1. [Executive Summary](#executive-summary)\n2. [Introduction to Wire-Speed Networking](#introduction-to-wire-speed-networking)\n3. [The Multi-Tenant Challenge](#the-multi-tenant-challenge)\n4. [Understanding DPUs, SmartNICs & IPUs](#understanding-dpus-smartnics--ipus)\n5. [Vendor Landscape](#vendor-landscape)\n6. [Architecture Deep Dive](#architecture-deep-dive)\n7. [Layer 7 Offload & Security Implications](#layer-7-offload--security-implications)\n8. [Implementation Patterns](#implementation-patterns)\n9. [Use Cases](#use-cases)\n10. [Security Attack Surfaces](#security-attack-surfaces)\n11. [Advanced Security Topics](#advanced-security-topics)\n12. [Performance Analysis](#performance-analysis)\n13. [Deployment Topologies](#deployment-topologies)\n14. [Best Practices](#best-practices)\n15. [Future Directions](#future-directions)\n16. [Appendix](#appendix)\n\n---\n\n## Executive Summary\n\n### What is Wire-Speed Tenant Isolation?\n\nWire-speed tenant isolation is the capability to enforce complete separation between multiple tenants (customers, workloads, or security domains) on shared infrastructure **at full network line rate** \u2014 typically 100-400 Gbps \u2014 with **sub-10 microsecond latency** and **zero packet loss**.\n\n### Why Does It Matter?\n\n| Challenge | Traditional Approach | Wire-Speed Approach |\n|-----------|---------------------|---------------------|\n| Latency | 50-500\u03bcs (software) | <10\u03bcs (hardware) |\n| Throughput | 10-40 Gbps | 100-400 Gbps |\n| CPU Overhead | 30-60% cores for networking | <5% (offloaded) |\n| Isolation Guarantee | Best-effort | Hardware-enforced |\n| Cost per Gbps | High | Low |\n\n### Key Statistics\n\n- **$4.88M** \u2014 Average cost of a data breach (IBM 2024)\n- **73%** \u2014 Attacks targeting application layer (Layer 7)\n- **400 Gbps** \u2014 Current wire-speed target for AI infrastructure\n- **667\u00d7** \u2014 AI traffic growth projected by 2027\n- **<10\u03bcs** \u2014 Target E-W latency for distributed AI training\n\n---\n\n## Introduction to Wire-Speed Networking\n\n### Defining \"Wire Speed\"\n\n**Wire speed** means processing every packet at the maximum rate the physical medium supports, with zero queuing delay.\n\n```mermaid\nflowchart LR\n    subgraph E100[\"100 Gbps Ethernet\"]\n        A1[\"Bit time: 10ps\"]\n        A2[\"Min packet 64B: 5.12ns\"]\n        A3[\"Max: 148.8M pps\"]\n        A4[\"Budget: 6.7ns/pkt\"]\n    end\n    subgraph E400[\"400 Gbps Ethernet\"]\n        B1[\"Bit time: 2.5ps\"]\n        B2[\"Min packet 64B: 1.28ns\"]\n        B3[\"Max: 595.2M pps\"]\n        B4[\"Budget: 1.68ns/pkt\"]\n    end\n    style E100 fill:#3498db,color:#fff\n    style E400 fill:#e74c3c,color:#fff\n```\n\n### The Physics Problem\n\nAt 400 Gbps, you have **1.68 nanoseconds** to:\n1. Receive the packet\n2. Parse headers (Ethernet, IP, TCP/UDP, application)\n3. Look up tenant context\n4. Apply security policies\n5. Make routing decisions\n6. Forward or drop\n\n**Light travels only 50cm in 1.68 nanoseconds.** Software cannot achieve this \u2014 hardware acceleration is mandatory.\n\n### Historical Evolution\n\n| Era | Speed | Isolation Method | Latency |\n|-----|-------|------------------|---------|\n| 1990s | 10 Mbps | VLANs | 1-10ms |\n| 2000s | 1 Gbps | VRFs, ACLs | 100\u03bcs-1ms |\n| 2010s | 10-40 Gbps | SDN, vSwitches | 50-200\u03bcs |\n| 2020s | 100-400 Gbps | DPU/SmartNIC | <10\u03bcs |\n| 2025+ | 800 Gbps-1.6 Tbps | Integrated DPU | <5\u03bcs |\n\n---\n\n## The Multi-Tenant Challenge\n\n### Why Multi-Tenancy is Hard\n\nMulti-tenancy means multiple customers share the same physical infrastructure while maintaining complete isolation. This creates fundamental tensions:\n\n```mermaid\ngraph TD\n    I[\"\ud83d\udd12 ISOLATION\"]\n    P[\"\u26a1 PERFORMANCE\"]\n    C[\"\ud83d\udcb0 COST EFFICIENCY\"]\n    I --- P\n    P --- C\n    C --- I\n    style I fill:#ff6b6b,color:#fff\n    style P fill:#4ecdc4,color:#fff\n    style C fill:#45b7d1,color:#fff\n```\n\n**The Fundamental Tension:**\n\nYou can optimize for any two of these properties, but the third will suffer:\n- **High Isolation + High Performance** = Expensive (dedicated hardware per tenant)\n- **High Isolation + Cost Efficient** = Slow (software-based isolation)\n- **High Performance + Cost Efficient** = Weak isolation (shared resources)\n\nWire-speed tenant isolation with DPUs attempts to solve all three by moving isolation enforcement to dedicated hardware that operates at line rate.\n\n### Isolation Requirements\n\n#### 1. Data Plane Isolation\n- No packet leakage between tenants\n- No timing side-channels\n- No shared buffer attacks\n\n#### 2. Control Plane Isolation\n- Independent routing tables\n- Separate policy engines\n- Isolated management interfaces\n\n#### 3. Performance Isolation\n- Guaranteed bandwidth\n- Latency SLAs\n- Fair queuing under contention\n\n#### 4. Security Isolation\n- Independent encryption keys\n- Separate attestation chains\n- Isolated failure domains\n\n### The AI Infrastructure Challenge\n\nAI workloads create unique multi-tenancy challenges:\n\n| Characteristic | Impact on Isolation |\n|---------------|---------------------|\n| **Collective Operations** | All-reduce requires synchronized communication across thousands of GPUs |\n| **Microbursts** | Traffic spikes of 100\u00d7 average in <100\u03bcs |\n| **Elephant Flows** | Single flows consuming 100+ Gbps for minutes |\n| **Latency Sensitivity** | 1\u03bcs additional latency = measurable training slowdown |\n| **East-West Dominance** | 80%+ traffic stays within datacenter |\n\n```\nAI Traffic Pattern Example (8,000 GPU cluster):\n\nNormal state:     \u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591  20% utilization\nGradient sync:    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  100% for 50ms\nIdle:             \u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591  0% for 200ms\nNext sync:        \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  100% for 50ms\n\nThis bursty pattern breaks traditional QoS mechanisms.\n```\n\n---\n\n## Understanding DPUs, SmartNICs & IPUs\n\n### Terminology Clarification\n\n| Term | Full Name | Primary Function | Key Vendor |\n|------|-----------|------------------|------------|\n| **SmartNIC** | Smart Network Interface Card | Accelerated networking | Mellanox, Intel, Broadcom |\n| **DPU** | Data Processing Unit | Infrastructure offload | NVIDIA, AMD, Marvell |\n| **IPU** | Infrastructure Processing Unit | Cloud infrastructure | Intel |\n| **xPU** | Generic accelerator | Various | Multiple |\n\n### Architecture Comparison\n\n```mermaid\nflowchart LR\n    subgraph NIC[\"Traditional NIC\"]\n        N1[\"MAC + PHY\"]\n    end\n    subgraph SNIC[\"SmartNIC\"]\n        S1[\"Programmable<br/>P4, eBPF\"]\n    end\n    subgraph DPUCARD[\"DPU\"]\n        D1[\"ARM + HW Accel<br/>Full Pipeline\"]\n    end\n    NIC -->|\"All pkts\"| CPU1[\"CPU\"]\n    SNIC -->|\"Filtered\"| CPU2[\"CPU\"]\n    DPUCARD -->|\"Exceptions\"| CPU3[\"CPU\"]\n    style NIC fill:#e74c3c,color:#fff\n    style SNIC fill:#f39c12,color:#fff\n    style DPUCARD fill:#27ae60,color:#fff\n```\n\n**Evolution of Network Offload:**\n\n| Generation | Technology | CPU Load | Programmability | Use Case |\n|------------|------------|----------|-----------------|----------|\n| Gen 1 | Traditional NIC | 100% | None | Basic connectivity |\n| Gen 2 | TOE/RDMA NIC | 70-80% | Fixed function | Storage, HPC |\n| Gen 3 | SmartNIC | 30-50% | P4/eBPF | SDN, basic isolation |\n| Gen 4 | DPU/IPU | <10% | Full stack | Multi-tenant cloud |\n\n**Key Differentiator:** DPUs include general-purpose ARM cores running a full Linux environment, enabling complex control plane logic while hardware handles data plane at line rate.\n\n### Key Capabilities Matrix\n\n| Capability | Basic NIC | SmartNIC | DPU/IPU |\n|-----------|-----------|----------|---------|\n| Line-rate forwarding | \u2717 | \u2713 | \u2713 |\n| VXLAN/Geneve offload | \u2717 | \u2713 | \u2713 |\n| Stateful firewall | \u2717 | Partial | \u2713 |\n| TLS termination | \u2717 | \u2717 | \u2713 |\n| Storage offload (NVMe-oF) | \u2717 | \u2717 | \u2713 |\n| Full OS on NIC | \u2717 | \u2717 | \u2713 |\n| Custom application hosting | \u2717 | \u2717 | \u2713 |\n\n---\n\n## Vendor Landscape\n\n### NVIDIA (BlueField DPU)\n\n#### Product Line\n\n| Model | Cores | Network | Accelerators | Use Case |\n|-------|-------|---------|--------------|----------|\n| **BlueField-2** | 8\u00d7 A72 | 2\u00d7100G / 1\u00d7200G | Crypto, RegEx | Production standard |\n| **BlueField-3** | 16\u00d7 A78 | 2\u00d7200G / 1\u00d7400G | +DPA engines | AI infrastructure |\n| **BlueField-4** | 16\u00d7 Grace | 1\u00d7800G | +CXL, NVLink | Next-gen AI clouds |\n\n#### Key Technologies\n\n**DOCA SDK (Data Center Infrastructure on a Chip Architecture)**\n```c\n// Example: DOCA Flow API for tenant isolation\nstruct doca_flow_match match = {\n    .outer = {\n        .l3_type = DOCA_FLOW_L3_TYPE_IP4,\n        .src_ip = tenant_a_subnet,\n    },\n};\n\nstruct doca_flow_actions actions = {\n    .decap = true,\n    .mod_dst_mac = tenant_a_gateway_mac,\n};\n\n// Hardware-enforced at 400Gbps line rate\ndoca_flow_pipe_add_entry(pipe, &match, &actions, NULL);\n```\n\n**NVIDIA ASTRA (Advanced Secure Trusted Resource Architecture)**\n- Hardware root of trust\n- Secure boot chain\n- Runtime attestation\n- Encrypted memory regions\n\n#### Pricing (Approximate)\n\n| Model | List Price | Volume Price |\n|-------|-----------|--------------|\n| BlueField-2 100G | $2,000-3,000 | $1,500-2,000 |\n| BlueField-3 200G | $4,000-6,000 | $3,000-4,500 |\n| BlueField-3 400G | $8,000-12,000 | $6,000-9,000 |\n\n---\n\n### Intel (IPU)\n\n#### Product Line\n\n| Model | Architecture | Network | Target |\n|-------|-------------|---------|--------|\n| **Mount Evans (E2000)** | ARM + FPGA | 2\u00d7100G | Cloud providers |\n| **Oak Springs Canyon** | Xeon-D + FPGA | 2\u00d7100G | Enterprise |\n| **Hotrock** | Custom ASIC | 400G | Hyperscalers |\n\n#### Key Technologies\n\n**IPDK (Infrastructure Programmer Development Kit)**\n```p4\n// P4 program for tenant isolation on Intel IPU\ncontrol TenantIsolation(inout headers_t hdr,\n                        inout metadata_t meta) {\n    table tenant_lookup {\n        key = {\n            hdr.vxlan.vni : exact;\n        }\n        actions = {\n            set_tenant_context;\n            drop;\n        }\n        size = 64000;  // 64K tenants\n    }\n    \n    apply {\n        tenant_lookup.apply();\n    }\n}\n```\n\n**Intel TDX Integration**\n- Trusted Domain Extensions for confidential computing\n- IPU acts as trusted intermediary\n- Memory encryption keys managed by IPU\n\n---\n\n### AMD (Pensando DPU)\n\n#### Product Line\n\n| Model | Cores | Network | Differentiator |\n|-------|-------|---------|----------------|\n| **DSC-25** | 16\u00d7 P4 cores | 2\u00d725G | Entry-level |\n| **DSC-100** | 16\u00d7 P4 cores | 2\u00d7100G | Mainstream |\n| **DSC-200** | 16\u00d7 P4 cores | 2\u00d7200G | High performance |\n\n#### Key Technologies\n\n**P4-Native Architecture**\n- Entire data plane programmable in P4\n- No fixed-function limitations\n- True wire-speed programmability\n\n**Pensando Policy and Services Manager (PSM)**\n- Centralized policy management\n- Multi-tenant orchestration\n- API-driven automation\n\n---\n\n### Marvell (OCTEON & Prestera)\n\n#### Product Line\n\n| Family | Type | Target Market |\n|--------|------|---------------|\n| **OCTEON 10** | DPU | Cloud & Enterprise |\n| **Prestera** | Switch ASIC | Network switches |\n| **ARMADA** | SoC | Edge computing |\n\n#### Key Features\n- Inline MACsec at 400G\n- Hardware RegEx for DPI\n- Native ARM ecosystem\n\n---\n\n### Broadcom (Memory)\n\n#### Product Line\n\n| Model | Type | Capability |\n|-------|------|------------|\n| **Memory 220P** | SmartNIC | 2\u00d725G, limited offload |\n| **Stingray** | DPU | 2\u00d7100G, full offload |\n| **Thor** | Next-gen | 400G, CXL support |\n\n---\n\n### Fungible (Now Microsoft)\n\nMicrosoft acquired Fungible in 2023 for its DPU technology.\n\n#### Key Innovation\n- **Fungible Data Center** \u2014 Composable infrastructure\n- **TrueFabric** \u2014 Lossless Ethernet at scale\n- Now integrated into Azure infrastructure\n\n---\n\n### Vendor Comparison Matrix\n\n| Vendor | Max Speed | ARM Cores | P4 Support | Market Position |\n|--------|-----------|-----------|------------|-----------------|\n| NVIDIA | 400G (800G soon) | 16 | DOCA Flow | AI Leader |\n| Intel | 200G (400G soon) | 8-16 | Native P4 | Cloud Provider Focus |\n| AMD | 200G | 16 P4 | Native P4 | Programmability |\n| Marvell | 400G | 24 | Limited | Networking Focus |\n| Broadcom | 100G | 8 | Limited | Cost-Optimized |\n\n---\n\n## Architecture Deep Dive\n\n### Reference Architecture\n\n```mermaid\nflowchart TB\n    subgraph APPS[\"TENANT APPS\"]\n        TA[\"Tenant A\"]\n        TB[\"Tenant B\"]\n        TC[\"Tenant C\"]\n    end\n    HOST[\"HOST OS + OVS\"]\n    PCIE[\"PCIe\"]\n    subgraph DPUBOX[\"DPU\"]\n        CTX[\"Tenant Contexts<br/>VNI 100/200/300\"]\n        HW[\"HW Accelerators<br/>Crypto, RegEx, DMA\"]\n        ARM[\"ARM + DOCA\"]\n    end\n    NET[\"2\u00d7200G / 1\u00d7400G\"]\n    DCN[\"\ud83c\udf10 DC Network\"]\n    APPS --> HOST --> PCIE --> DPUBOX --> NET --> DCN\n    style APPS fill:#3498db,color:#fff\n    style HOST fill:#9b59b6,color:#fff\n    style DPUBOX fill:#27ae60,color:#fff\n    style NET fill:#e74c3c,color:#fff\n```\n\n### Packet Flow (Wire-Speed Path)\n\n```mermaid\nflowchart LR\n    P1[\"1\ufe0f\u20e3 Physical<br/>~100ns\"]\n    P2[\"2\ufe0f\u20e3 Parser<br/>~50ns\"]\n    P3[\"3\ufe0f\u20e3 Tenant Lookup<br/>~20ns\"]\n    P4[\"4\ufe0f\u20e3 Policy Engine<br/>~100ns\"]\n    P5[\"5\ufe0f\u20e3 Forwarding<br/>~30ns\"]\n    P6[\"6\ufe0f\u20e3 Header Mod<br/>~50ns\"]\n    P7[\"7\ufe0f\u20e3 Egress Queue<br/>~50ns\"]\n    P8[\"8\ufe0f\u20e3 Transmit<br/>~100ns\"]\n    P1 --> P2 --> P3 --> P4 --> P5 --> P6 --> P7 --> P8\n    style P1 fill:#1abc9c,color:#fff\n    style P2 fill:#2ecc71,color:#fff\n    style P3 fill:#3498db,color:#fff\n    style P4 fill:#9b59b6,color:#fff\n    style P5 fill:#e74c3c,color:#fff\n    style P6 fill:#f39c12,color:#fff\n    style P7 fill:#e67e22,color:#fff\n    style P8 fill:#1abc9c,color:#fff\n```\n\n**Total Pipeline Latency: ~500ns**\n\nThis is well under the 1.68ns budget per packet because of parallel pipeline processing - multiple packets are processed simultaneously at different stages.\n\n### Memory Architecture\n\n```mermaid\nflowchart TB\n    subgraph MEM[\"DPU Memory Hierarchy\"]\n        SRAM[\"\ud83d\udfe2 On-Chip SRAM<br/>50-100 MB | ~5ns\"]\n        HBM[\"\ud83d\udd35 HBM / GDDR<br/>8-32 GB | ~100ns\"]\n        DDR[\"\ud83d\udfe3 DDR4/DDR5<br/>16-64 GB | ~50-100ns\"]\n        HOSTMEM[\"\ud83d\udd34 Host Memory DMA<br/>~500ns-1\u03bcs\"]\n    end\n    SRAM --> HBM --> DDR --> HOSTMEM\n    style SRAM fill:#27ae60,color:#fff\n    style HBM fill:#3498db,color:#fff\n    style DDR fill:#9b59b6,color:#fff\n    style HOSTMEM fill:#e74c3c,color:#fff\n```\n\n**Memory Tier Usage:**\n| Tier | Contents | Access Pattern |\n|------|----------|----------------|\n| SRAM | Active flow tables, packet buffers | Every packet |\n| HBM/GDDR | Extended tables, statistics | Frequent lookups |\n| DDR | ARM subsystem, Linux kernel | Control plane |\n| Host Memory | Large packet queues, DMA buffers | Bulk transfers |\n\n**Design Principle:** Keep hot data (flow tables, counters) in SRAM for single-digit nanosecond access. Spill to HBM only when SRAM capacity is exceeded.\n\n---\n\n## Layer 7 Offload & Security Implications\n\n### What Gets Offloaded to Layer 7\n\n| Function | Layer | Complexity | Security Risk |\n|----------|-------|------------|---------------|\n| Switching | L2 | Low | Low |\n| Routing | L3 | Medium | Low |\n| Firewalling | L3-4 | Medium | Medium |\n| Load Balancing | L4-7 | High | Medium |\n| TLS Termination | L4-7 | High | High |\n| API Gateway | L7 | Very High | Very High |\n| WAF | L7 | Very High | Very High |\n| Deep Packet Inspection | L7 | Very High | Very High |\n\n### The Security Trade-off\n\n```mermaid\nflowchart LR\n    subgraph LOW[\"Lower Risk\"]\n        L23[\"L2-L3 Offload<br/>\u2022 Switching<br/>\u2022 Routing<br/>\u2022 Basic ACL\"]\n    end\n    subgraph HIGH[\"Higher Risk\"]\n        L47[\"L4-L7 Offload<br/>\u2022 TLS<br/>\u2022 WAF<br/>\u2022 DPI\"]\n    end\n    LOW -->|\"More Offload \u2192\"| HIGH\n    HIGH -->|\"More Attack Surface\"| RISK[\"\u26a0\ufe0f\"]\n    style LOW fill:#27ae60,color:#fff\n    style HIGH fill:#e74c3c,color:#fff\n```\n\n**Risk Assessment by Layer:**\n\n| Offload Type | Attack Surface | Vulnerability Impact | Recommendation |\n|--------------|----------------|---------------------|----------------|\n| L2 Switching | Minimal | MAC spoofing, VLAN hopping | Safe to offload |\n| L3 Routing | Low | Route injection | Safe with validation |\n| L4 Firewall | Medium | State table exhaustion | Offload with monitoring |\n| TLS Termination | High | Key exposure, protocol bugs | Careful evaluation |\n| WAF/DPI | Very High | Regex DoS, parser exploits | Consider hybrid approach |\n\n**Recommendation:** Start with L2-L4 offload where the security/performance tradeoff is favorable. Evaluate L7 offload on a case-by-case basis.\n\n### Attack Surface Expansion\n\nWhen you move logic to Layer 7 in hardware, you create:\n\n1. **Shared Memory Attack Surface**\n   - Host \u2194 DPU shared buffers\n   - Potential for buffer overflows\n   - Type confusion vulnerabilities\n\n2. **Complex Parsing Attack Surface**\n   - HTTP/2, gRPC, TLS parsers\n   - Protocol state machines\n   - Malformed input handling\n\n3. **Trust Boundary Attack Surface**\n   - PCIe interface\n   - DMA mappings\n   - Attestation chain\n\n4. **Visibility Blind Spots**\n   - Traffic processed entirely on DPU\n   - SOC tools may not see it\n   - Logging limitations\n\n---\n\n## Implementation Patterns\n\n### Pattern 1: Bump-in-the-Wire (Transparent)\n\n```mermaid\nflowchart LR\n    C[\"Client\"] --> D[\"DPU<br/>Bridge\"]\n    D --> S[\"Server\"]\n    style D fill:#3498db,color:#fff\n```\n\n**Characteristics:**\n- DPU acts as transparent bridge\n- No IP address on DPU  \n- Minimal configuration\n- Limited functionality\n\n**Use Case:** Simple traffic inspection, basic isolation\n\n**Use Case:** Simple traffic inspection, basic isolation\n\n---\n\n### Pattern 2: Gateway Mode\n\n```mermaid\nflowchart LR\n    C[\"Client<br/>10.0.1.x\"] --> D[\"DPU Gateway<br/>10.0.1.1 / 10.0.2.1\"]\n    D --> S[\"Server<br/>10.0.2.x\"]\n    style D fill:#27ae60,color:#fff\n```\n\n**Characteristics:**\n- DPU has IP addresses\n- Full L3 routing\n- NAT, firewalling\n- Complete isolation\n\n**Use Case:** Multi-tenant cloud, VPC implementation\n\n**Use Case:** Multi-tenant cloud, VPC implementation\n\n---\n\n### Pattern 3: Sidecar Mode\n\n```mermaid\nflowchart LR\n    subgraph SERVER[\"Server\"]\n        APP[\"Application\"] -->|localhost| DPU[\"DPU Sidecar\"]\n    end\n    NET[\"\ud83c\udf10 Network\"] <--> DPU\n    style DPU fill:#e74c3c,color:#fff\n    style APP fill:#3498db,color:#fff\n```\n\n**Characteristics:**\n- DPU handles all external traffic\n- Application only sees localhost\n- Full security enforcement\n- Zero application changes\n\n**Use Case:** Legacy application modernization, service mesh\n\n**Use Case:** Legacy application modernization, service mesh\n\n---\n\n### Pattern 4: Hypervisor Integration\n\n```mermaid\nflowchart TB\n    subgraph HV[\"Hypervisor\"]\n        subgraph VMS[\"Virtual Machines\"]\n            VM1[\"VM 1 Tenant A\"]\n            VM2[\"VM 2 Tenant B\"]\n            VM3[\"VM 3 Tenant A\"]\n        end\n        OVS[\"OVS Representor\"]\n    end\n    subgraph DPUCARD[\"DPU\"]\n        ESW[\"eSwitch HW\"]\n        POL[\"Policy Engine\"]\n    end\n    VM1 --> OVS\n    VM2 --> OVS\n    VM3 --> OVS\n    OVS -->|\"PCIe VFs\"| DPUCARD\n    style VMS fill:#9b59b6,color:#fff\n    style DPUCARD fill:#27ae60,color:#fff\n```\n\n**Characteristics:**\n- SR-IOV for direct VM access\n- Hardware eSwitch for isolation\n- OVS for control plane only\n- Maximum performance\n\n**Use Case:** Cloud infrastructure, OpenStack/Kubernetes\n\n**Use Case:** Cloud infrastructure, OpenStack/Kubernetes\n\n---\n\n### Pattern 5: Distributed Services Mesh\n\n```mermaid\nflowchart TB\n    subgraph K8S[\"Kubernetes Cluster\"]\n        subgraph N1[\"Node 1\"]\n            P1[\"Pod A-1\"]\n            D1[\"DPU\"]\n        end\n        subgraph N2[\"Node 2\"]\n            P2[\"Pod B-1\"]\n            D2[\"DPU\"]\n        end\n        subgraph N3[\"Node 3\"]\n            P3[\"Pod A-2\"]\n            D3[\"DPU\"]\n        end\n        FAB[\"Fabric\"]\n    end\n    P1 --> D1\n    P2 --> D2\n    P3 --> D3\n    D1 --> FAB\n    D2 --> FAB\n    D3 --> FAB\n    style N1 fill:#3498db,color:#fff\n    style N2 fill:#e74c3c,color:#fff\n    style N3 fill:#27ae60,color:#fff\n```\n\n**Characteristics:**\n- DPU per node\n- Distributed policy enforcement\n- Mesh encryption (mTLS)\n- Kubernetes CNI integration\n\n**Use Case:** Cloud-native applications, microservices\n\n**Use Case:** Cloud-native applications, microservices\n\n---\n\n## Use Cases\n\n### Use Case 1: Multi-Tenant AI Cloud\n\n**Scenario:** Cloud provider offering GPU-as-a-Service with strict tenant isolation\n\n**Requirements:**\n- 10,000+ tenants per region\n- 400 Gbps per GPU server\n- <10\u03bcs E-W latency\n- Zero cross-tenant data leakage\n- Per-tenant bandwidth guarantees\n\n**Architecture:**\n```mermaid\nflowchart TB\n    subgraph GPU[\"GPU Server\"]\n        subgraph GPUS[\"GPUs\"]\n            H1[\"H100 A\"]\n            H2[\"H100 A\"]\n            H3[\"H100 B\"]\n            H4[\"H100 B\"]\n        end\n        NV[\"NVSwitch\"]\n        subgraph BF3[\"BlueField-3 DPU\"]\n            TCA[\"Tenant A 200G\"]\n            TCB[\"Tenant B 200G\"]\n        end\n    end\n    H1 --> NV\n    H2 --> NV\n    H3 --> NV\n    H4 --> NV\n    NV --> BF3\n    BF3 -->|\"400G\"| DCF[\"\ud83c\udf10 Fabric\"]\n    style GPUS fill:#3498db,color:#fff\n    style BF3 fill:#27ae60,color:#fff\n    style NV fill:#9b59b6,color:#fff\n```\n\n**AI/GPU Cloud Isolation Requirements:**\n\n| Requirement | Implementation | Why It Matters |\n|-------------|----------------|----------------|\n| GPU Memory Isolation | MIG (Multi-Instance GPU) | Prevent cross-tenant GPU memory access |\n| Network Bandwidth | Per-tenant rate limiting | Guarantee training job network SLAs |\n| NVLink Isolation | Hardware partitioning | Prevent inter-GPU side channels |\n| Storage I/O | Separate NVMe namespaces | Checkpoint/restore isolation |\n\n**Key Challenge:** AI training workloads generate sustained 400 Gbps traffic for extended periods. Traditional burst-based traffic engineering assumptions don't apply.\n\n**Implementation:**\n```python\n# DOCA Flow configuration for AI tenant isolation\ndef configure_ai_tenant(tenant_id, vni, bandwidth_gbps, gpu_ids):\n    # Create tenant context\n    tenant_ctx = doca_flow_create_tenant_context(\n        vni=vni,\n        bandwidth=bandwidth_gbps * 1e9,\n        priority=DOCA_FLOW_PRIORITY_HIGH\n    )\n    \n    # Configure GPU-to-GPU flows (intra-tenant)\n    for src_gpu in gpu_ids:\n        for dst_gpu in gpu_ids:\n            if src_gpu != dst_gpu:\n                doca_flow_add_gpu_flow(\n                    tenant_ctx,\n                    src_gpu=src_gpu,\n                    dst_gpu=dst_gpu,\n                    action=ALLOW,\n                    rdma=True  # Enable GPUDirect RDMA\n                )\n    \n    # Block cross-tenant GPU communication\n    doca_flow_add_default_rule(\n        tenant_ctx,\n        action=DROP,\n        log=True\n    )\n    \n    # Enable telemetry\n    doca_telemetry_enable(\n        tenant_ctx,\n        metrics=['bandwidth', 'latency', 'drops'],\n        interval_ms=100\n    )\n    \n    return tenant_ctx\n```\n\n---\n\n### Use Case 2: Financial Services Trading Infrastructure\n\n**Scenario:** Ultra-low latency trading platform with regulatory isolation requirements\n\n**Requirements:**\n- <5\u03bcs network latency\n- Nanosecond-precision timestamping\n- Complete audit trail\n- MiFID II / Reg NMS compliance\n- Deterministic performance\n\n**Architecture:**\n```mermaid\nflowchart TB\n    subgraph TRADE[\"Trading Server\"]\n        subgraph APP[\"Trading App\"]\n            STRAT[\"Strategy\"]\n            ORD[\"Orders\"]\n            MKT[\"Market Data\"]\n        end\n        subgraph DPU[\"BlueField DPU\"]\n            TS[\"\u23f1\ufe0f HW Timestamp\"]\n            CA[\"Client A Flow\"]\n            CB[\"Client B Flow\"]\n            COMP[\"\u2705 Compliance\"]\n        end\n    end\n    APP -->|\"DPDK\"| DPU\n    style APP fill:#3498db,color:#fff\n    style DPU fill:#27ae60,color:#fff\n```\n\n**Financial Services Requirements:**\n\n| Feature | Specification | Regulatory Driver |\n|---------|---------------|-------------------|\n| Timestamping | PTP, <100ns accuracy | MiFID II, CAT |\n| Order Isolation | Per-client flow queues | Best execution |\n| Pre-trade Risk | Hardware rate checks | Risk management |\n| Audit Trail | Every packet logged | SEC Rule 17a-4 |\n\n**Latency Budget (Market Data to Order):**\n- Wire to DPU: 100ns\n- DPU parsing: 50ns\n- Risk check: 200ns\n- Order formatting: 100ns\n- DPU to wire: 100ns\n- **Total: ~550ns** (sub-microsecond)\n\n**Key Features:**\n- Hardware PTP for nanosecond timestamps\n- Kernel bypass for minimum latency\n- Hardware-enforced pre-trade risk checks\n- Complete order audit trail\n- Client flow isolation\n\n---\n\n### Use Case 3: Telecommunications 5G Core\n\n**Scenario:** 5G User Plane Function (UPF) with subscriber isolation\n\n**Requirements:**\n- 100Gbps per UPF instance\n- 1M+ subscribers per node\n- 3GPP compliance\n- Network slicing support\n- <1ms user plane latency\n\n**Architecture:**\n```mermaid\nflowchart TB\n    subgraph UPF[\"5G UPF Server\"]\n        subgraph UPFAPP[\"UPF App\"]\n            SMF[\"SMF\"]\n            AMF[\"AMF\"]\n            PCF[\"PCF\"]\n        end\n        subgraph DPU[\"BlueField DPU\"]\n            S1[\"eMBB 100G\"]\n            S2[\"URLLC <1ms\"]\n            S3[\"mMTC 1M\"]\n            GTP[\"GTP-U\"]\n        end\n    end\n    UPFAPP --> DPU\n    N3[\"\ud83d\udce1 N3\"] <--> DPU\n    DPU <--> N6[\"\ud83c\udf10 N6\"]\n    style UPFAPP fill:#3498db,color:#fff\n    style DPU fill:#27ae60,color:#fff\n```\n\n**5G Network Slice Characteristics:**\n\n| Slice Type | Bandwidth | Latency | Density | Use Case |\n|------------|-----------|---------|---------|----------|\n| eMBB | 100+ Gbps | 10ms | Medium | Video streaming, downloads |\n| URLLC | 10 Mbps | <1ms | Low | Autonomous vehicles, remote surgery |\n| mMTC | 1 Mbps | Relaxed | 1M/km\u00b2 | IoT sensors, smart meters |\n\n**DPU Offload Benefits:**\n- GTP-U encap/decap at 100+ Gbps line rate\n- Per-subscriber QoS enforcement in hardware\n- Usage metering without CPU overhead\n- Slice isolation with zero cross-talk\n\n---\n\n### Use Case 4: Healthcare Data Platform\n\n**Scenario:** Multi-tenant healthcare analytics with HIPAA compliance\n\n**Requirements:**\n- PHI isolation (HIPAA)\n- Encryption at rest and in transit\n- Complete audit logging\n- Data residency controls\n- Breach detection\n\n**Security Controls:**\n```mermaid\nflowchart TB\n    subgraph HEALTH[\"Healthcare Platform\"]\n        subgraph HOSP[\"Hospitals\"]\n            HA[\"Hospital A\"]\n            HB[\"Hospital B\"]\n            HC[\"Hospital C\"]\n        end\n        subgraph DPUL[\"DPU Layer\"]\n            ENC[\"\ud83d\udd10 Encryption\"]\n            ACC[\"\ud83d\udd11 Access Control\"]\n            AUD[\"\ud83d\udccb Audit\"]\n        end\n    end\n    HA --> DPUL\n    HB --> DPUL\n    HC --> DPUL\n    style HOSP fill:#e74c3c,color:#fff\n    style DPUL fill:#27ae60,color:#fff\n```\n\n**Healthcare Compliance Requirements:**\n\n| Regulation | Requirement | DPU Implementation |\n|------------|-------------|-------------------|\n| HIPAA | PHI encryption in transit | MACsec + IPsec at line rate |\n| HIPAA | Access controls | Hardware-enforced RBAC |\n| HIPAA | Audit trails | Per-packet logging |\n| HITECH | Breach notification | Real-time anomaly detection |\n| GDPR | Data residency | Geo-fencing in hardware |\n\n**Security Controls:**\n- **Encryption:** AES-256-GCM with per-tenant keys, HSM integration for key management\n- **Access Control:** Role-based policies, time-based access windows, geographic restrictions\n- **Audit:** Every packet logged with tamper-proof storage, real-time SIEM feed for compliance\n\n---\n\n### Use Case 5: Gaming Infrastructure\n\n**Scenario:** Cloud gaming platform with latency-critical multi-tenancy\n\n**Requirements:**\n- <20ms total latency (network + processing)\n- 60fps video streaming\n- Fair resource allocation\n- Anti-cheat integration\n- Regional failover\n\n---\n\n## Security Attack Surfaces\n\n### Attack Surface Map\n\n```mermaid\nflowchart TB\n    subgraph ATTACKS[\"Attack Surface\"]\n        HOST[\"\ud83d\udda5\ufe0f HOST<br/>PCIe, DMA, Drivers\"]\n        DPUSIDE[\"\ud83d\udd27 DPU<br/>Firmware, ARM OS\"]\n        NETSIDE[\"\ud83c\udf10 NETWORK<br/>Physical, MITM\"]\n    end\n    subgraph CROSS[\"\u26a0\ufe0f CROSS-CUTTING\"]\n        C1[\"Side channels<br/>Supply chain<br/>Tenant escape\"]\n    end\n    HOST --> CROSS\n    DPUSIDE --> CROSS\n    NETSIDE --> CROSS\n    style HOST fill:#e74c3c,color:#fff\n    style DPUSIDE fill:#f39c12,color:#fff\n    style NETSIDE fill:#9b59b6,color:#fff\n    style CROSS fill:#2c3e50,color:#fff\n```\n\n**Detailed Attack Vectors:**\n\n| Surface | Attack Vector | Impact | Mitigation |\n|---------|---------------|--------|------------|\n| **Host Side** | PCIe BAR manipulation | Memory access | IOMMU strict mode |\n| | DMA attacks | Data exfiltration | ATS validation |\n| | Driver vulnerabilities | Privilege escalation | Signed drivers |\n| **DPU Side** | Firmware tampering | Persistent compromise | Secure boot, attestation |\n| | ARM OS exploits | Control plane takeover | Minimal attack surface |\n| | Accelerator bugs | Data corruption | Input validation |\n| **Network** | Physical tap | Traffic interception | MACsec encryption |\n| | MITM attacks | Data manipulation | Certificate pinning |\n| | Replay attacks | Session hijacking | Sequence numbers, timestamps |\n| **Cross-Cutting** | Timing side-channels | Information leakage | Constant-time operations |\n| | Supply chain | Backdoors | Vendor audits, attestation |\n| | Tenant escape | Full compromise | Defense in depth |\n\n### Attack Vector Details\n\n#### 1. DMA Attacks\n\n**Description:** Direct Memory Access allows DPU to read/write host memory without CPU involvement.\n\n**Attack Scenarios:**\n- Pre-boot credential theft\n- Kernel memory manipulation\n- Encryption key extraction\n- Code injection\n\n**Mitigations:**\n```\nIOMMU Configuration:\n\n# Enable IOMMU in strict mode\nGRUB_CMDLINE_LINUX=\"intel_iommu=on iommu=strict\"\n\n# Or for AMD\nGRUB_CMDLINE_LINUX=\"amd_iommu=on iommu=strict\"\n\n# Verify IOMMU groups\nfor d in /sys/kernel/iommu_groups/*/devices/*; do\n    n=$(basename $(dirname $(dirname $d)))\n    echo \"IOMMU Group $n: $(lspci -nns ${d##*/})\"\ndone\n```\n\n---\n\n#### 2. Shared Memory Attacks\n\n**Description:** Buffer overflows or type confusion in host-DPU shared memory regions.\n\n**Example Vulnerability:**\n```c\n// Vulnerable code pattern\nstruct shared_buffer {\n    uint32_t length;     // Attacker controlled\n    uint8_t data[];      // Variable length\n};\n\nvoid process_packet(struct shared_buffer *buf) {\n    // BUG: No bounds check against actual buffer size\n    char local[256];\n    memcpy(local, buf->data, buf->length);  // Overflow!\n}\n```\n\n**Secure Pattern:**\n```c\n// Secure code pattern\nvoid process_packet(struct shared_buffer *buf, size_t buf_size) {\n    // Validate length against actual buffer\n    if (buf->length > buf_size - sizeof(uint32_t)) {\n        log_security_event(\"Buffer overflow attempt\");\n        return;\n    }\n    \n    // Additional sanity check\n    if (buf->length > MAX_PACKET_SIZE) {\n        log_security_event(\"Invalid packet size\");\n        return;\n    }\n    \n    char local[MAX_PACKET_SIZE];\n    memcpy(local, buf->data, buf->length);\n}\n```\n\n---\n\n#### 3. Firmware Attacks\n\n**Description:** Compromising DPU firmware to gain persistent access.\n\n**Attack Chain:**\n```mermaid\nflowchart TB\n    A1[\"1\ufe0f\u20e3 Supply Chain\"] --> A1a[\"Malicious firmware in manufacturing\"]\n    A2[\"2\ufe0f\u20e3 Update Server\"] --> A2a[\"MITM on firmware update\"]\n    A3[\"3\ufe0f\u20e3 Local Exploit\"] --> A3a[\"ARM Linux vuln \u2192 Flash modified FW\"]\n    A4[\"4\ufe0f\u20e3 Physical Access\"] --> A4a[\"JTAG/debug \u2192 Flash extraction\"]\n    style A1 fill:#e74c3c,color:#fff\n    style A2 fill:#f39c12,color:#fff\n    style A3 fill:#9b59b6,color:#fff\n    style A4 fill:#2c3e50,color:#fff\n```\n\n**Mitigations:**\n- Secure boot with hardware root of trust\n- Signed firmware updates\n- Runtime attestation\n- Disable debug interfaces in production\n\n---\n\n#### 4. Side-Channel Attacks\n\n**Description:** Extracting secrets through timing, power, or electromagnetic analysis.\n\n**Timing Attack Example:**\n```python\n# Detecting tenant activity through timing\nimport time\n\ndef measure_dpu_response_time(packet):\n    start = time.perf_counter_ns()\n    send_packet(packet)\n    wait_for_response()\n    end = time.perf_counter_ns()\n    return end - start\n\n# Collect timing samples\ntimings = []\nfor i in range(10000):\n    t = measure_dpu_response_time(probe_packet)\n    timings.append(t)\n\n# Analyze timing distribution\n# Bimodal distribution may indicate cache hit/miss\n# revealing information about other tenants\nanalyze_timing_distribution(timings)\n```\n\n**Mitigations:**\n- Constant-time operations for sensitive paths\n- Cache partitioning between tenants\n- Noise injection\n- Rate limiting per tenant\n\n---\n\n#### 5. Tenant Escape\n\n**Description:** Breaking out of tenant isolation to access other tenants' data.\n\n**Escape Vectors:**\n1. **VNI Spoofing:** Crafting packets with other tenants' VXLAN Network Identifiers\n2. **Flow Table Poisoning:** Manipulating shared flow tables\n3. **Resource Exhaustion:** DoS against shared resources to cause fallback to insecure path\n4. **Metadata Leakage:** Extracting tenant info from error messages or timing\n\n---\n\n## Advanced Security Topics\n\n### DMA & IOMMU Deep Dive\n\n```mermaid\nflowchart LR\n    subgraph BAD[\"\u274c Without IOMMU\"]\n        DPU1[\"DPU\"] -->|\"Physical Addr\"| MEM1[\"ALL Host Memory\"]\n    end\n    subgraph GOOD[\"\u2705 With IOMMU\"]\n        DPU2[\"DPU\"] -->|\"IO Virtual\"| IOMMU[\"IOMMU\"]\n        IOMMU -->|\"Physical\"| MEM2[\"Restricted Memory\"]\n    end\n    style BAD fill:#e74c3c,color:#fff\n    style GOOD fill:#27ae60,color:#fff\n```\n\n**IOMMU Page Table Structure:**\n\n| Level | Entry | Contents |\n|-------|-------|----------|\n| Root Table | Entry 0 | Context Table (DPU) |\n| Context Table | Domain 0 | Tenant A pages |\n| Context Table | Domain 1 | Tenant B pages |\n| Context Table | Domain 2 | Shared pages |\n\n**Why IOMMU Matters:**\nWithout IOMMU protection, a compromised DPU could read or write any location in host memory, potentially accessing other tenants' data or injecting malicious code. IOMMU provides hardware-enforced memory isolation that cannot be bypassed by software.\n\n### eBPF/XDP Security\n\n**eBPF (Extended Berkeley Packet Filter)** allows running sandboxed programs in the kernel. **XDP (eXpress Data Path)** runs eBPF at the NIC driver level for wire-speed processing.\n\n**Security Risks:**\n```c\n// Example: eBPF verifier bypass (historical CVE pattern)\nSEC(\"xdp\")\nint exploit(struct xdp_md *ctx) {\n    void *data = (void *)(long)ctx->data;\n    void *data_end = (void *)(long)ctx->data_end;\n    \n    // Verifier tracks bounds...\n    if (data + 100 > data_end)\n        return XDP_DROP;\n    \n    // But complex control flow can confuse it\n    int offset = some_complex_calculation();\n    \n    // Verifier may not catch this OOB access\n    char *ptr = data + offset;  // Could be out of bounds!\n    char leak = *ptr;           // Information leak\n    \n    return XDP_PASS;\n}\n```\n\n**Mitigations:**\n- Keep kernel updated (verifier improvements)\n- Limit eBPF to privileged users\n- Use eBPF LSM for additional checks\n- Audit all loaded eBPF programs\n\n### Multi-Tenant Side-Channel Analysis\n\n```mermaid\nsequenceDiagram\n    participant A as Tenant A\n    participant C as DPU Cache\n    participant B as Tenant B\n    A->>C: Access pattern A (fills cache)\n    B->>C: Access pattern B (evicts A's data)\n    A->>C: Measure access time (slow = B accessed)\n    Note over A,B: Result: A infers B's patterns\n```\n\n**Attack Mechanism Explained:**\n1. Tenant A fills specific cache lines with known data\n2. Tenant B's workload evicts some of A's cached data\n3. Tenant A measures access latency to its original data\n4. Slow access indicates cache miss = B accessed that memory region\n5. By repeating this process, A can reconstruct B's access patterns\n\n**Mitigations:**\n- Cache partitioning (Intel CAT, AMD QoS)\n- Time-constant operations for security-critical code\n- Cache line flushing between tenant context switches\n- Statistical noise injection\n\n**Defense: Cache Partitioning**\n```mermaid\nflowchart LR\n    subgraph CACHE[\"L3 Cache 30 MB\"]\n        TA[\"Tenant A<br/>8 MB<br/>Ways 0-3\"]\n        TB[\"Tenant B<br/>8 MB<br/>Ways 4-7\"]\n        TC[\"Tenant C<br/>8 MB<br/>Ways 8-11\"]\n        SH[\"Shared<br/>6 MB<br/>Ways 12-14\"]\n    end\n    style TA fill:#e74c3c,color:#fff\n    style TB fill:#27ae60,color:#fff\n    style TC fill:#3498db,color:#fff\n    style SH fill:#9b59b6,color:#fff\n```\n\n```bash\n# Allocate cache ways\npqos -e \"llc:0=0x000F\"   # Tenant A: ways 0-3\npqos -e \"llc:1=0x00F0\"   # Tenant B: ways 4-7\npqos -e \"llc:2=0x0F00\"   # Tenant C: ways 8-11\n# Assign tenants\npqos -a \"core:0-7=0\"     # Tenant A cores\npqos -a \"core:8-15=1\"    # Tenant B cores\n```\n\n---\n\n## Performance Analysis\n\n### Latency Breakdown\n\n```mermaid\npie title Latency Budget 10\u03bcs Total\n    \"App Processing 2.0\u03bcs\" : 2.0\n    \"Host OS 0.5\u03bcs\" : 0.5\n    \"PCIe 0.3\u03bcs\" : 0.3\n    \"DPU 1.5\u03bcs\" : 1.5\n    \"Wire 0.5\u03bcs\" : 0.5\n    \"Switch x2 1.0\u03bcs\" : 1.0\n    \"Remote DPU 1.5\u03bcs\" : 1.5\n    \"Remote Host 2.7\u03bcs\" : 2.7\n```\n\n**DPU Processing Breakdown (1.5\u03bcs total):**\n- Parser: 0.2\u03bcs\n- Tenant lookup: 0.1\u03bcs\n- Policy engine: 0.5\u03bcs\n- Header modification: 0.2\u03bcs\n- Queue management: 0.5\u03bcs\n\nThis latency budget assumes optimized configurations with hardware offload enabled.\n\n### Throughput Analysis\n\n```mermaid\nflowchart LR\n    T1[\"Theoretical<br/>400 Gbps\"] --> T2[\"FEC<br/>390.6<br/>-2.3%\"]\n    T2 --> T3[\"Gaps<br/>381<br/>-4.8%\"]\n    T3 --> T4[\"VXLAN<br/>357<br/>-10.8%\"]\n    T4 --> T5[\"Encrypt<br/>340<br/>-15%\"]\n    T5 --> T6[\"Actual<br/>320<br/>-20%\"]\n    style T1 fill:#27ae60,color:#fff\n    style T6 fill:#e74c3c,color:#fff\n```\n\n**Packets Per Second (64-byte minimum packets):**\n- Theoretical maximum: 595.2 Mpps\n- With encapsulation overhead: 476.2 Mpps\n- Practical sustainable limit: 400.0 Mpps\n\nThe gap between theoretical and practical throughput accounts for real-world factors including inter-packet gaps, flow table lookups, and policy enforcement overhead.\n\n### Benchmark Results\n\n| Vendor | Model | Throughput | Latency (p99) | Tenants |\n|--------|-------|------------|---------------|---------|\n| NVIDIA | BF-3 400G | 380 Gbps | 3.2 \u03bcs | 64K |\n| Intel | IPU E2100 | 190 Gbps | 4.1 \u03bcs | 32K |\n| AMD | DSC-200 | 190 Gbps | 3.8 \u03bcs | 16K |\n| Marvell | OCTEON 10 | 380 Gbps | 4.5 \u03bcs | 48K |\n\n---\n\n## Deployment Topologies\n\n### Topology 1: Spine-Leaf (Standard)\n\n```mermaid\nflowchart TB\n    subgraph SPINE[\"Spine Layer\"]\n        S1[\"Spine 1<br/>400G\"]\n        S2[\"Spine 2<br/>400G\"]\n    end\n    subgraph LEAF[\"Leaf Layer\"]\n        L1[\"Leaf 1\"]\n        L2[\"Leaf 2\"]\n        L3[\"Leaf 3\"]\n        L4[\"Leaf 4\"]\n    end\n    subgraph SERVERS[\"Server Layer\"]\n        SV1[\"Server+DPU\"]\n        SV2[\"Server+DPU\"]\n        SV3[\"Server+DPU\"]\n        SV4[\"Server+DPU\"]\n    end\n    S1 --> L1\n    S1 --> L2\n    S1 --> L3\n    S1 --> L4\n    S2 --> L1\n    S2 --> L2\n    S2 --> L3\n    S2 --> L4\n    L1 --> SV1\n    L2 --> SV2\n    L3 --> SV3\n    L4 --> SV4\n    style SPINE fill:#e74c3c,color:#fff\n    style LEAF fill:#3498db,color:#fff\n    style SERVERS fill:#27ae60,color:#fff\n```\n\n**Characteristics:**\n- 2 hops maximum (any server to any server)\n- Predictable latency\n- Easy to scale horizontally\n- Non-blocking with proper oversubscription\n\n**Best For:** General-purpose data center workloads\n\n### Topology 2: Rail-Optimized (AI Training)\n\n```mermaid\nflowchart TB\n    subgraph RAILS[\"Rail Switches\"]\n        R0[\"Rail 0\"]\n        R1[\"Rail 1\"]\n        R2[\"Rail 2\"]\n    end\n    subgraph SV[\"Server\"]\n        G0[\"GPU 0\"]\n        G1[\"GPU 1\"]\n        G2[\"GPU 2\"]\n        G3[\"GPU 3\"]\n        DPU[\"DPU\"]\n    end\n    R0 --> G0\n    R0 --> G3\n    R1 --> G1\n    R2 --> G2\n    style R0 fill:#e74c3c,color:#fff\n    style R1 fill:#27ae60,color:#fff\n    style R2 fill:#3498db,color:#fff\n    style SV fill:#2c3e50,color:#fff\n```\n\n**Characteristics:**\n- Optimized for all-reduce operations\n- Each GPU connects to dedicated rail switch\n- Minimizes cross-rail traffic\n- Ideal for large-scale training\n\n**Best For:** AI/ML training clusters with heavy collective operations\n\n### Topology 3: Dragonfly+ (Hyperscale)\n\n```mermaid\nflowchart TB\n    subgraph G0[\"Group 0\"]\n        S00[\"S0\"] --- S01[\"S1\"] --- S02[\"S2\"]\n        SRV0[\"Servers\"]\n    end\n    subgraph G1[\"Group 1\"]\n        S10[\"S0\"] --- S11[\"S1\"] --- S12[\"S2\"]\n        SRV1[\"Servers\"]\n    end\n    S00 --> SRV0\n    S01 --> SRV0\n    S02 --> SRV0\n    S10 --> SRV1\n    S11 --> SRV1\n    S12 --> SRV1\n    S00 ---|\"Global\"| S10\n    S01 ---|\"Global\"| S11\n    S02 ---|\"Global\"| S12\n    style G0 fill:#3498db,color:#fff\n    style G1 fill:#27ae60,color:#fff\n```\n\n**Characteristics:**\n- Optimal for 10,000+ node clusters\n- Minimizes global link usage\n- Adaptive routing\n- Used by frontier supercomputers\n\n**Best For:** Hyperscale deployments, HPC clusters\n\n---\n\n## Best Practices\n\n### 1. Security Best Practices\n\n**\ud83d\udd10 SECURITY CHECKLIST**\n\n| \u2705 | Item | Action |\n|---|------|--------|\n| \u25a1 | IOMMU strict mode | `dmesg \\| grep -i iommu` |\n| \u25a1 | Firmware signatures | Check vendor cert chain |\n| \u25a1 | Secure boot | HW root of trust |\n| \u25a1 | Network segmentation | Separate mgmt/data planes |\n| \u25a1 | Encryption | MACsec + IPsec with HW accel |\n| \u25a1 | Telemetry | Real-time SIEM export |\n| \u25a1 | Rate limiting | Prevent DoS/side-channel |\n| \u25a1 | Security audits | Pen testing, FW analysis |\n| \u25a1 | Incident response | DPU-specific runbooks |\n| \u25a1 | Firmware updates | Vendor security advisories |\n\n### 2. Performance Best Practices\n\n**\u26a1 PERFORMANCE CHECKLIST**\n\n| Category | Item |\n|----------|------|\n| **Hardware** | \u25a1 SR-IOV, \u25a1 RSS config, \u25a1 Jumbo frames, \u25a1 IRQ pinning, \u25a1 NUMA-aware |\n| **DPU** | \u25a1 Pre-populate flows, \u25a1 HW offload, \u25a1 Queue depths, \u25a1 ECN, \u25a1 Buffer tuning |\n| **Host** | \u25a1 Huge pages, \u25a1 Disable C-states, \u25a1 CPU governor=performance, \u25a1 isolcpus, \u25a1 Busy polling |\n\n### 3. Operational Best Practices\n\n**\ud83d\udd27 DAY-2 OPERATIONS**\n\n| Category | Items |\n|----------|-------|\n| **Monitoring** | Throughput, Latency p50/p95/p99, Drops, Errors, Resources, Security events |\n| **Alerting** | p99>10\u03bcs, Drops>0.01%, BW>90%, Flow table>80%, Policy violations, FW attestation |\n| **Maintenance** | FW: Rolling updates, Config: Blue-green, Capacity: Pre-staged, Emergency: Escalation |\n\n---\n\n## Future Directions\n\n### Technology Roadmap\n\n```mermaid\ntimeline\n    title Technology Roadmap\n    2024-2025 : 400G standard : BlueField-3 : CXL 2.0 : ARM v9\n    2025-2026 : 800G early : CXL 3.0 : AI on DPU : BlueField-4\n    2026-2027 : 800G mainstream : 1.6T dev : DPU-GPU : Photonics\n    2028+ : 1.6T mainstream : 3.2T dev : Quantum-safe : Optical I/O\n```\n\n### Emerging Capabilities\n\n| Capability | Timeline | Impact |\n|------------|----------|--------|\n| CXL Memory Pooling | 2025 | Shared memory across servers |\n| In-network Computing | 2025 | Aggregation in switches |\n| AI on DPU | 2026 | Inline inference |\n| Optical DPU | 2028 | 10\u00d7 density improvement |\n\n---\n\n## Appendix\n\n### A. Glossary\n\n| Term | Definition |\n|------|------------|\n| **DPU** | Data Processing Unit - A programmable processor for infrastructure offload |\n| **SmartNIC** | Network interface card with programmable packet processing |\n| **IPU** | Infrastructure Processing Unit (Intel's term for DPU) |\n| **VXLAN** | Virtual Extensible LAN - Overlay network encapsulation |\n| **VNI** | VXLAN Network Identifier - Tenant identifier in VXLAN |\n| **SR-IOV** | Single Root I/O Virtualization - Hardware virtualization for NICs |\n| **RDMA** | Remote Direct Memory Access - Zero-copy networking |\n| **RoCE** | RDMA over Converged Ethernet |\n| **ECN** | Explicit Congestion Notification |\n| **PFC** | Priority Flow Control - Lossless Ethernet mechanism |\n| **DCQCN** | Data Center QCN - Congestion control for RDMA |\n| **eSwitch** | Embedded switch in SmartNIC/DPU |\n| **IOMMU** | Input-Output Memory Management Unit |\n| **DOCA** | Data Center Infrastructure on a Chip Architecture (NVIDIA SDK) |\n| **P4** | Programming Protocol-independent Packet Processors (language) |\n| **eBPF** | Extended Berkeley Packet Filter |\n| **XDP** | eXpress Data Path |\n\n### B. Reference Specifications\n\n**NVIDIA BlueField-3:**\n- 16\u00d7 ARM Cortex-A78 cores @ 3.0 GHz\n- 400 Gbps network throughput\n- 16 GB on-board DDR5\n- 900 Gb/s PCIe Gen5\n- Hardware crypto: 200 Gbps IPsec/MACsec\n- 64K+ tenant support\n\n**Intel IPU E2100:**\n- 16\u00d7 ARM Neoverse N1 cores\n- FPGA acceleration\n- 200 Gbps network\n- P4-programmable pipeline\n- Intel TDX integration\n\n### C. Compliance Frameworks\n\n| Framework | Relevance to Wire-Speed Isolation |\n|-----------|----------------------------------|\n| **SOC 2** | Logical isolation controls, access logging |\n| **PCI DSS** | Network segmentation, encryption, monitoring |\n| **HIPAA** | PHI isolation, audit trails, encryption |\n| **FedRAMP** | Boundary protection, continuous monitoring |\n| **GDPR** | Data isolation, right to erasure |\n\n### D. Vendor Documentation Links\n\n- **NVIDIA DOCA:** https://developer.nvidia.com/doca\n- **Intel IPDK:** https://ipdk.io\n- **AMD Pensando:** https://www.amd.com/pensando\n- **Marvell OCTEON:** https://www.marvell.com/products/infrastructure-processors\n- **P4 Language:** https://p4.org\n\n### E. CVE References\n\n| CVE | Component | Impact |\n|-----|-----------|--------|\n| CVE-2022-21125 | Intel MMIO | Side-channel data leak |\n| CVE-2021-26708 | Linux vsock | VM escape |\n| CVE-2020-8835 | eBPF verifier | Privilege escalation |\n| CVE-2019-14899 | VPN | Traffic hijacking |\n\n---\n\n## Document Information\n\n**Version:** 1.0  \n**Last Updated:** January 2025  \n**Author:** Subramaniyam Venkata Pooni \u2022 CS\u00b2B Technologies  \n**License:** \u00a9 2025 CS\u00b2B Technologies. All rights reserved.\n\n---\n\n*This document is intended for technical audiences implementing wire-speed tenant isolation. Always verify vendor specifications and conduct security assessments before production deployment.*\n";

        async function render() {
            document.getElementById('content').innerHTML = marked.parse(md);
            document.getElementById('content').classList.remove('loading');
            await mermaid.run({ querySelector: '.mermaid' });
        }
        render();
    </script>
</body>
</html>